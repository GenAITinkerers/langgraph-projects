{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f31b4dba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b833f976",
      "metadata": {
        "id": "b833f976"
      },
      "source": [
        "# Task\n",
        "Integrate the LLM-powered `moat_analysis_node` into the existing LangGraph workflow by updating the `AgentState` with 'margin_score' and 'report_summary', modifying the `margin_analysis_agent` to return 'margin_score', updating the `ranking_agent` to use 'margin_score' and 'moat_score' from the state, and modifying the `report_agent` to incorporate 'report_summary'. Recompile the graph, run the analysis for the predefined list of companies, and then present the ranked list along with a summary of the successful integration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8759e0b",
      "metadata": {
        "id": "d8759e0b"
      },
      "source": [
        "## Update AgentState\n",
        "\n",
        "### Subtask:\n",
        "Modify the `AgentState` TypedDict to include 'margin_score' and 'report_summary' which are now produced by the `margin_analysis_agent` and `moat_analysis_node` respectively. This ensures the shared memory of the agents correctly reflects the outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7109bcb8",
      "metadata": {
        "id": "7109bcb8"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `AgentState` to include new fields `margin_score` and `report_summary`. I will locate the existing `AgentState` definition and update it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "603460d0",
      "metadata": {
        "id": "603460d0"
      },
      "source": [
        "## Update `margin_analysis_agent`\n",
        "\n",
        "### Subtask:\n",
        "Modify the `margin_analysis_agent` function to return `margin_score` in its output dictionary. This ensures that the calculated margin score is propagated through the `AgentState` for subsequent agents to use.\n",
        "\n",
        "#### Instructions\n",
        "1. Locate the `margin_analysis_agent` function definition.\n",
        "2. Ensure the function returns a dictionary containing `\"margin_score\": score`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dd06ddb",
      "metadata": {
        "id": "1dd06ddb"
      },
      "source": [
        "## Update `margin_analysis_agent`\n",
        "\n",
        "### Subtask:\n",
        "Modify the `margin_analysis_agent` function to return `margin_score` in its output dictionary. This ensures that the calculated margin score is propagated through the `AgentState` for subsequent agents to use.\n",
        "\n",
        "#### Instructions\n",
        "1. Locate the `margin_analysis_agent` function definition.\n",
        "2. Ensure the function returns a dictionary containing `\"margin_score\": score`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb4bf0e",
      "metadata": {
        "id": "ffb4bf0e"
      },
      "source": [
        "**Reasoning**:\n",
        "The `margin_analysis_agent` function already correctly returns the `margin_score` as a dictionary, fulfilling the requirement of the subtask. I will provide the current definition of the function for completeness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e4dad0d",
      "metadata": {
        "id": "6e4dad0d"
      },
      "source": [
        "**Reasoning**:\n",
        "The `margin_analysis_agent` function already correctly returns the `margin_score` as a dictionary, fulfilling the requirement of the subtask. I will provide the current definition of the function for completeness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f15479",
      "metadata": {
        "id": "18f15479"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps updated the `AgentState` and ensured `margin_analysis_agent` returns `margin_score`. Now, I need to replace the placeholder `moat_analysis_agent` with the LLM-powered `moat_analysis_node` to correctly populate `moat_score` and `report_summary` in the `AgentState`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a219be96",
      "metadata": {
        "id": "a219be96"
      },
      "source": [
        "## Update `moat_analysis_agent`\n",
        "\n",
        "### Subtask:\n",
        "Replace the placeholder `moat_analysis_agent` with the LLM-powered `moat_analysis_node` function. This will integrate the LLM to dynamically determine the `moat_score` and generate a `report_summary` based on the company's information.\n",
        "\n",
        "#### Instructions\n",
        "1. Locate the existing `moat_analysis_agent` function definition.\n",
        "2. Replace its content with the code from the `moat_analysis_node` function, ensuring it returns a dictionary with `moat_score` and `report_summary`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61983a15",
      "metadata": {
        "id": "61983a15"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step updated the `AgentState` and ensured `margin_analysis_agent` returns `margin_score`. Now, I need to redefine the `moat_analysis_agent` with the LLM-powered `moat_analysis_node` to correctly populate `moat_score` and `report_summary` in the `AgentState`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e25a8c2",
      "metadata": {
        "id": "5e25a8c2"
      },
      "source": [
        "## Update `ranking_agent`\n",
        "\n",
        "### Subtask:\n",
        "Modify the `ranking_agent` function to utilize the newly available `margin_score` and the `moat_score` (now directly populated by the LLM) from the `AgentState` for its calculations. The previous `operating_margin` in the formula should be replaced with `margin_score`.\n",
        "\n",
        "#### Instructions\n",
        "1. Locate the `ranking_agent` function definition.\n",
        "2. Update the formula to use `state['margin_score']` instead of `state['operating_margin']`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "489760fc",
      "metadata": {
        "id": "489760fc"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the subtask to update the `ranking_agent`. Now, I will provide the code to modify the `ranking_agent` to use `state['margin_score']` and `state['moat_score']` for its calculations, as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c881ce",
      "metadata": {
        "id": "d5c881ce"
      },
      "source": [
        "## Update `report_agent`\n",
        "\n",
        "### Subtask:\n",
        "Modify the `report_agent` function to include the `report_summary` from the `AgentState` in its generated report. This will provide a more comprehensive output incorporating the LLM's analysis of the company's moat.\n",
        "\n",
        "#### Instructions\n",
        "1. Locate the `report_agent` function definition.\n",
        "2. Update the `summary` string to include `state['report_summary']`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89e7aa3d",
      "metadata": {
        "id": "89e7aa3d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the subtask to update the `report_agent`. Now, I will provide the code to modify the `report_agent` to use `state['report_summary']` in its output, as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "205aae93",
      "metadata": {
        "id": "205aae93"
      },
      "outputs": [],
      "source": [
        "def report_agent(state: AgentState):\n",
        "    \"\"\"Produces investor-ready output.\"\"\"\n",
        "    summary = f\"Ranked Profile for {state['company_name']}: Score {state['final_score']}. Moat Summary: {state['report_summary']}\"\n",
        "    return {\"report\": summary}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d68c100b",
      "metadata": {
        "id": "d68c100b"
      },
      "source": [
        "## Recompile and Run the Graph\n",
        "\n",
        "### Subtask:\n",
        "Recompile the LangGraph workflow after all the agent modifications. Then, run the analysis for the predefined list of companies and present the ranked list along with a summary of the successful integration.\n",
        "\n",
        "#### Instructions\n",
        "1. Recompile the workflow using `workflow.compile()`.\n",
        "2. Iterate through the `companies` list, invoking the `app` for each company.\n",
        "3. Collect the results and sort them by `final_score` in descending order.\n",
        "4. Print the ranked list and a concluding summary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45260e14",
      "metadata": {
        "id": "45260e14"
      },
      "source": [
        "**Reasoning**:\n",
        "All agent functions have been updated. Now, I will recompile the workflow, iterate through the companies, run the analysis, and present the ranked list as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eedcd100",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eedcd100",
        "outputId": "0980f431-4391-4311-cb3b-7c27e1257873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangGraph workflow compiled successfully.\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "from typing import Annotated, List, TypedDict\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "import json\n",
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "# Prompt for moat analysis\n",
        "MOAT_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a Senior Equity Research Analyst. Your task is to score the 'Moat' of a company\n",
        "contributing to the AI Factory Capital Stack.\n",
        "\n",
        "Company: {company_name}\n",
        "Sector: {sector}\n",
        "\n",
        "Criteria for Moat Score (0-5):\n",
        "1. Architectural lock-in (e.g., proprietary standards like CUDA)\n",
        "2. Ecosystem dominance (design wins, reference architectures)\n",
        "3. Switching costs / standard-setting influence\n",
        "4. Scarcity or bottleneck position in the supply chain\n",
        "\n",
        "Analysis Task:\n",
        "- Briefly describe the company's differentiation in the AI Factory ecosystem.\n",
        "- Assign a Moat Score from 0 to 5 based on the criteria above.\n",
        "\n",
        "Return ONLY a JSON object in this format:\n",
        "{{\n",
        "  \"moat_score\": integer,\n",
        "  \"narrative\": \"string summary\"\n",
        "}}\n",
        "\"\"\")\n",
        "\n",
        "# Set your API Key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "\n",
        "# Initialize the model\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\", # or \"gemini-1.5-pro\" for deeper reasoning\n",
        "    temperature=0.2          # Lower temperature = more consistent scoring\n",
        ")\n",
        "\n",
        "# Assuming llm, MOAT_PROMPT are already defined and updated\n",
        "\n",
        "\n",
        "# 1. Define the State: This is the \"shared memory\" of your agents\n",
        "class AgentState(TypedDict):\n",
        "    company_name: str\n",
        "    sector: str  # e.g., Cooling, Power, Networking [cite: 41-45]\n",
        "    operating_margin: float\n",
        "    moat_score: int\n",
        "    growth_forecast: float\n",
        "    final_score: float\n",
        "    report: str\n",
        "    margin_score: int\n",
        "    report_summary: str\n",
        "\n",
        "# 2. Define the Node Functions (The Agents)\n",
        "\n",
        "def margin_analysis_agent(state: AgentState):\n",
        "    \"\"\"Normalizes operating margin strength.\"\"\"\n",
        "    margin = state['operating_margin']\n",
        "    if margin > 0.40: score = 5\n",
        "    elif margin > 0.30: score = 4\n",
        "    elif margin > 0.20: score = 3\n",
        "    elif margin > 0.10: score = 2\n",
        "    else: score = 1\n",
        "    return {\"margin_score\": score}\n",
        "\n",
        "def moat_analysis_agent(state: AgentState):\n",
        "    \"\"\"The Moat Specialist Agent 'thinks' about defensibility.\"\"\"\n",
        "    # Format the prompt with current state data\n",
        "    chain = MOAT_PROMPT | llm\n",
        "    response = chain.invoke({\n",
        "        \"company_name\": state[\"company_name\"],\n",
        "        \"sector\": state[\"sector\"]\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response.content)\n",
        "    except json.JSONDecodeError as e:\n",
        "        cleaned_content = response.content.strip().replace('```json', '').replace('```', '')\n",
        "        try:\n",
        "            result = json.loads(cleaned_content)\n",
        "        except json.JSONDecodeError as e_cleaned:\n",
        "            return {\"moat_score\": 0, \"report_summary\": \"LLM failed to return valid JSON.\"}\n",
        "\n",
        "    return {\n",
        "        \"moat_score\": result[\"moat_score\"],\n",
        "        \"report_summary\": result[\"narrative\"]\n",
        "    }\n",
        "\n",
        "def ranking_agent(state: AgentState):\n",
        "    \"\"\"Computes Total AI Factory Growth Score.\"\"\"\n",
        "    final = (state['moat_score'] * state['margin_score']) * state['growth_forecast']\n",
        "    return {\"final_score\": final}\n",
        "\n",
        "def report_agent(state: AgentState):\n",
        "    \"\"\"Produces investor-ready output.\"\"\"\n",
        "    summary = f\"Ranked Profile for {state['company_name']}: Score {state['final_score']}. Moat Summary: {state['report_summary']}\"\n",
        "    return {\"report\": summary}\n",
        "\n",
        "# 3. Build the Graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"analyze_margin\", margin_analysis_agent)\n",
        "workflow.add_node(\"analyze_moat\", moat_analysis_agent)\n",
        "workflow.add_node(\"calculate_rank\", ranking_agent)\n",
        "workflow.add_node(\"generate_report\", report_agent)\n",
        "\n",
        "# Define the flow (Edges)\n",
        "workflow.set_entry_point(\"analyze_margin\")\n",
        "workflow.add_edge(\"analyze_margin\", \"analyze_moat\")\n",
        "workflow.add_edge(\"analyze_moat\", \"calculate_rank\")\n",
        "workflow.add_edge(\"calculate_rank\", \"generate_report\")\n",
        "workflow.add_edge(\"generate_report\", END)\n",
        "\n",
        "# Recompile the app after all changes\n",
        "app = workflow.compile()\n",
        "print(\"LangGraph workflow compiled successfully.\")\n",
        "\n",
        "# Example input data based on your project scope\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fAXYI96YDONf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAXYI96YDONf",
        "outputId": "b2191ea1-bc64-4920-e201-017356073f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running analysis for Vertiv...\n",
            "\n",
            "Running analysis for Arista Networks...\n",
            "\n",
            "Running analysis for Schneider Electric...\n",
            "\n",
            "Running analysis for NVIDIA...\n",
            "\n",
            "--- Top Companies Ranking (TAFGS Score) ---\n",
            "1. NVIDIA | Score: 45.00 | Moat Summary: NVIDIA's moat in the AI Factory ecosystem is exceptionally robust, stemming from its full-stack approach encompassing leading-edge hardware, proprietary software, and high-speed networking. The cornerstone is CUDA, its parallel computing platform, which represents a formidable architectural lock-in and the de facto standard for AI development, creating immense switching costs for developers and enterprises. NVIDIA dominates the AI compute ecosystem with pervasive design wins across hyperscalers and research, establishing reference architectures for virtually all major AI models. Its extensive software libraries and developer community further entrench this dominance. Furthermore, NVIDIA holds a strategic bottleneck position due to its reliance on scarce advanced packaging technologies (like TSMC's CoWoS) for its high-performance GPUs, securing critical supply chain advantage. This combination of technological leadership, ecosystem control, and supply chain leverage creates a near-unassailable competitive advantage in the burgeoning AI infrastructure market.\n",
            "2. Arista Networks | Score: 20.00 | Moat Summary: Arista Networks plays a crucial role in the AI Factory by providing high-performance, low-latency Ethernet switches essential for connecting GPUs and storage in large-scale AI clusters. Its core differentiation stems from its Extensible Operating System (EOS), which offers a highly programmable, open, and robust network operating system, creating significant operational lock-in and automation advantages for customers. While not possessing a proprietary hardware standard akin to NVIDIA's CUDA, Arista is a leading proponent and architect of open Ethernet solutions for AI, actively building an ecosystem and gaining traction with hyperscalers and enterprises as a scalable and cost-effective alternative to InfiniBand. The switching costs are high, as customers deeply integrate Arista's EOS into their network operations and automation frameworks. Arista's integrated hardware and software solution, combined with its strategic positioning and strong design wins in the nascent open Ethernet AI fabric market, establish a strong competitive moat, making it a critical and difficult-to-replace component in the AI infrastructure build-out.\n",
            "3. Schneider Electric | Score: 11.50 | Moat Summary: Schneider Electric is a foundational enabler for AI factories, providing the critical physical infrastructure required for high-density AI compute. This includes advanced power distribution, high-efficiency UPS systems, and sophisticated cooling solutions (including liquid cooling essential for high-power GPUs). Their EcoStruxure platform integrates hardware and software, offering comprehensive data center infrastructure management (DCIM) and energy optimization, which is crucial for the extreme power and thermal demands of AI workloads.\n",
            "\n",
            "1.  **Architectural lock-in:** The EcoStruxure platform creates a proprietary, integrated ecosystem for managing data center power, cooling, and operations. Once deeply embedded, this architecture makes it challenging and costly for customers to switch components or software, fostering significant lock-in.\n",
            "2.  **Ecosystem dominance:** Schneider is a global leader in data center physical infrastructure, boasting extensive design wins with hyperscalers and large enterprises building AI-centric data centers. They are a preferred and trusted vendor for mission-critical deployments, influencing industry best practices.\n",
            "3.  **Switching costs / standard-setting influence:** Switching costs are exceptionally high. Replacing core power and cooling infrastructure (UPS, PDUs, chillers) is a massive, disruptive, and capital-intensive undertaking, often requiring significant downtime. Schneider's solutions are widely considered industry benchmarks for reliability, efficiency, and safety in critical environments.\n",
            "4.  **Scarcity or bottleneck position:** Schneider is one of a very limited number of global vendors with the scale, expertise, and integrated offerings to meet the extreme power, thermal, and reliability demands of modern AI factories, especially concerning advanced liquid cooling and intelligent power management. This positions them as a critical, high-capacity supplier in a market with few alternatives at this scale and capability.\n",
            "4. Vertiv | Score: 11.20 | Moat Summary: Vertiv provides essential high-density power and advanced cooling solutions, particularly liquid cooling, critical for the extreme power and thermal demands of AI data centers. Their moat is built on high switching costs associated with deeply integrated infrastructure solutions, making it complex and expensive for customers to change providers once a data center is designed and deployed. Vertiv benefits from strong ecosystem dominance, with established relationships and design wins among hyperscalers and server OEMs, positioning them as a go-to partner for AI infrastructure build-outs. While not possessing a proprietary software standard like CUDA, their specialized engineering, intellectual property in thermal management, and global service capabilities create a significant barrier to entry. As demand for AI compute surges, Vertiv occupies a bottleneck position as one of a limited number of scaled providers capable of delivering the sophisticated cooling and power infrastructure required, making them an indispensable component of the AI factory capital stack.\n",
            "\n",
            "--- Integration Summary ---\n",
            "The LLM-powered moat analysis has been successfully integrated into the LangGraph workflow.\n",
            "The AgentState now includes 'margin_score' and 'report_summary'.\n",
            "The 'margin_analysis_agent' correctly populates 'margin_score'.\n",
            "The 'moat_analysis_agent' (LLM-powered) dynamically determines 'moat_score' and generates 'report_summary'.\n",
            "The 'ranking_agent' uses 'margin_score' and 'moat_score' for calculations.\n",
            "The 'report_agent' incorporates the LLM's 'report_summary' into the final output.\n"
          ]
        }
      ],
      "source": [
        "companies = [\n",
        "    {\"company_name\": \"Vertiv\", \"sector\": \"Cooling/Power\", \"operating_margin\": 0.15, \"growth_forecast\": 1.40},\n",
        "    {\"company_name\": \"Arista Networks\", \"sector\": \"Networking\", \"operating_margin\": 0.35, \"growth_forecast\": 1.25},\n",
        "    {\"company_name\": \"Schneider Electric\", \"sector\": \"Power\", \"operating_margin\": 0.18, \"growth_forecast\": 1.15},\n",
        "    {\"company_name\": \"NVIDIA\", \"sector\": \"Compute/AI Hardware\", \"operating_margin\": 0.60, \"growth_forecast\": 1.80}\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for co in companies:\n",
        "    print(f\"\\nRunning analysis for {co['company_name']}...\")\n",
        "    output = app.invoke(co)\n",
        "    results.append(output)\n",
        "\n",
        "# Sort by the TAFGS score (Highest to Lowest)\n",
        "ranked_list = sorted(results, key=lambda x: x['final_score'], reverse=True)\n",
        "print(\"\\n--- Top Companies Ranking (TAFGS Score) ---\")\n",
        "for rank, item in enumerate(ranked_list, 1):\n",
        "    print(f\"{rank}. {item['company_name']} | Score: {item['final_score']:.2f} | Moat Summary: {item['report_summary']}\")\n",
        "\n",
        "print(\"\\n--- Integration Summary ---\")\n",
        "print(\"The LLM-powered moat analysis has been successfully integrated into the LangGraph workflow.\")\n",
        "print(\"The AgentState now includes 'margin_score' and 'report_summary'.\")\n",
        "print(\"The 'margin_analysis_agent' correctly populates 'margin_score'.\")\n",
        "print(\"The 'moat_analysis_agent' (LLM-powered) dynamically determines 'moat_score' and generates 'report_summary'.\")\n",
        "print(\"The 'ranking_agent' uses 'margin_score' and 'moat_score' for calculations.\")\n",
        "print(\"The 'report_agent' incorporates the LLM's 'report_summary' into the final output.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63dad83",
      "metadata": {
        "id": "d63dad83"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The integrated LangGraph workflow successfully analyzed the predefined list of companies, providing the following ranked order based on their Total AI Factory Growth Score (TAFGS):\n",
        "1.  **NVIDIA**: Score 45.00\n",
        "2.  **Arista Networks**: Score 20.00\n",
        "3.  **Schneider Electric**: Score 11.50\n",
        "4.  **Vertiv**: Score 11.20\n",
        "\n",
        "The integration of the LLM-powered `moat_analysis_node` into the existing LangGraph workflow was successful, with all required modifications implemented and verified through execution.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `AgentState` was successfully updated to include 'margin\\_score' and 'report\\_summary', facilitating shared memory across agents.\n",
        "*   The `margin_analysis_agent` correctly populates the `margin_score` based on the operating margin.\n",
        "*   The `moat_analysis_agent` was successfully replaced with an LLM-powered function, dynamically determining the `moat_score` and generating a `report_summary` based on company information. Robust error handling for JSON parsing was included.\n",
        "*   The `ranking_agent` now correctly utilizes both the `moat_score` (from the LLM) and the `margin_score` (from the margin analysis) to compute the `final_score`.\n",
        "*   The `report_agent` was modified to incorporate the LLM-generated `report_summary` into the final investor-ready output, providing more comprehensive insights.\n",
        "*   The entire LangGraph workflow was recompiled and executed successfully for all companies, producing a ranked list and detailed reports.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The successful integration of the LLM-powered `moat_analysis_node` demonstrates the flexibility and extensibility of the LangGraph framework for incorporating advanced AI capabilities into analytical workflows.\n",
        "*   Future enhancements could include refining the LLM prompts for `moat_analysis_agent` to extract more detailed or specific aspects of a company's defensibility, or implementing a feedback loop to improve LLM response quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cd6dd1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e72dd88",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e58fb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# todo\n",
        "1) understand the whole code and run item\n",
        "2) understand how to start using LLM rathe than using hard coded\n",
        "3) run end to end code with LLM ModuleNotFoundError\n",
        "\n",
        "\n",
        "4) create a project out of the code in jupyter notebook\n",
        "5) break code in module and keep in different files, folder as a project\n",
        "6) create a docker image and run it in local container\n",
        "7) run in minikube"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "anomaly",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
